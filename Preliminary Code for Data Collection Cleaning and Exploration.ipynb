{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the EIA Data By Merging Power Plant and Generator Data to Detail the Various Energy Sources Used by Each Plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of years to loop over\n",
    "years = range(2014, 2024)\n",
    "\n",
    "# List to store DataFrames for each year\n",
    "merged_data = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    # Read the plant and generator data for the current year\n",
    "    plant_file = f\"C:\\\\Users\\\\kaavy\\\\OneDrive\\\\Documents\\\\Sci4GA Internship\\\\DATA on electricity powerplants from EIA\\\\{year}\\\\2___Plant_Y{year}.xlsx\"\n",
    "    generator_file = f\"C:\\\\Users\\\\kaavy\\\\OneDrive\\\\Documents\\\\Sci4GA Internship\\\\DATA on electricity powerplants from EIA\\\\{year}\\\\3_1_Generator_Y{year}.xlsx\"\n",
    "    \n",
    "    # Read the data\n",
    "    plant_og_df = pd.read_excel(plant_file)\n",
    "    generator_df = pd.read_excel(generator_file)\n",
    "    plant_df = plant_og_df[plant_og_df['State'] == 'GA']\n",
    "    \n",
    "    # Find unique values in the 'Technology' column\n",
    "    unique_technologies = generator_df['Technology'].unique()\n",
    "    unique_technologies = unique_technologies[~pd.isna(unique_technologies)]  # Remove NaN values\n",
    "\n",
    "    # Group by 'Plant Code' and 'Technology', count generators\n",
    "    tech_counts = generator_df.groupby(['Plant Code', 'Technology']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Merge aggregated technology data back to the plant_df\n",
    "    merged_df = plant_df.merge(tech_counts, on='Plant Code', how='left')\n",
    "\n",
    "    # Fill NaN values (if any) with 0 for generator counts\n",
    "    merged_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Now select only the columns that exist in merged_df and correspond to the technologies\n",
    "    valid_technologies = [tech for tech in unique_technologies if tech in merged_df.columns]\n",
    "\n",
    "    # Use idxmax to find the dominant technology based on the valid columns\n",
    "    # merged_df['Dominant Technology'] = merged_df[valid_technologies].idxmax(axis=1)\n",
    "\n",
    "    # Add a 'Year' column\n",
    "    merged_df['Year'] = year\n",
    "\n",
    "    # Retain only relevant columns\n",
    "    columns_to_keep = ['Plant Code', 'Plant Name', 'Latitude', 'Longitude', 'State', 'Year'] + valid_technologies\n",
    "    merged_df = merged_df[columns_to_keep]\n",
    "\n",
    "    # Append the merged data for the current year to the list\n",
    "    merged_data.append(merged_df)\n",
    "\n",
    "# Concatenate all the years into a single DataFrame\n",
    "final_df = pd.concat(merged_data, ignore_index=True)\n",
    "# Convert Year column to Date (set the first day of each year)\n",
    "final_df['Year'] = pd.to_datetime(final_df['Year'], format='%Y')\n",
    "\n",
    "# Save the concatenated DataFrame to an Excel file\n",
    "#output_path = r\"C:\\Users\\kaavy\\OneDrive\\Documents\\Sci4GA Internship\\Combined_Plant_Data_2014_to_2023.xlsx\"\n",
    "#final_df.to_excel(output_path, index=False)\n",
    "\n",
    "#print(f\"File with combined data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the Total Number of Generators for Each Energy Source from 2014 to 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_plant = pd.read_excel(r\"C:\\Users\\kaavy\\OneDrive\\Documents\\Sci4GA Internship\\Combined_Plant_Data_GA_2014_to_2023.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to sum\n",
    "target_columns = [\n",
    "    'Conventional Steam Coal',\n",
    "    'Conventional Hydroelectric',\n",
    "    'Petroleum Liquids',\n",
    "    'Natural Gas Fired Combined Cycle',\n",
    "    'Other Waste Biomass',\n",
    "    'Natural Gas Fired Combustion Turbine',\n",
    "    'Natural Gas with Compressed Air Storage',\n",
    "    'Natural Gas Internal Combustion Engine',\n",
    "    'Nuclear',\n",
    "    'Natural Gas Steam Turbine',\n",
    "    'Onshore Wind Turbine',\n",
    "    'All Other',\n",
    "    'Landfill Gas',\n",
    "    'Municipal Solid Waste',\n",
    "    'Geothermal',\n",
    "    'Hydroelectric Pumped Storage',\n",
    "    'Batteries',\n",
    "    'Solar Photovoltaic',\n",
    "    'Wood/Wood Waste Biomass',\n",
    "    'Other Gases',\n",
    "    'Other Natural Gas',\n",
    "    'Petroleum Coke',\n",
    "    'Coal Integrated Gasification Combined Cycle',\n",
    "    'Solar Thermal without Energy Storage',\n",
    "    'Solar Thermal with Energy Storage',\n",
    "    'Flywheels',\n",
    "    'Offshore Wind Turbine'\n",
    "]\n",
    "\n",
    "# Group by year and sum the target columns\n",
    "result = combined_plant.groupby('Year')[target_columns].sum()\n",
    "\n",
    "# Reset index for a cleaner output\n",
    "result = result.reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Monthly Energy Generation Data for Georgia from EIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # Library for making HTTP requests to the API\n",
    "import pandas as pd\n",
    "\n",
    "api_key = \"TYbnbyZAB6i2W9v3hzyqHXTyAhQufNdjPdJYYA2Z\"\n",
    "endpoint = \"https://api.eia.gov/v2/electricity/facility-fuel/data\"\n",
    "\n",
    "# Initialize empty list to store all data\n",
    "all_data = [] # Empty list to store all retrieved data\n",
    "offset = 0 # Starting point for pagination, helps retrieve data in chunks of 5000 records\n",
    "\n",
    "while True:\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"frequency\": \"monthly\", # Data granularity\n",
    "        \"data[0]\": \"generation\",\n",
    "        \"data[1]\": \"gross-generation\",\n",
    "        \"facets[state][]\": \"GA\",\n",
    "        \"start\": \"2014-01\",\n",
    "        \"end\": \"2023-12\",\n",
    "        \"sort[0][column]\": \"period\",\n",
    "        \"sort[0][direction]\": \"desc\",\n",
    "        \"offset\": offset,\n",
    "        \"length\": 5000 # Maximum records per request\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(endpoint, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()[\"response\"][\"data\"]\n",
    "        \n",
    "        if not data:  # If no more data is returned, break the loop\n",
    "            break\n",
    "            \n",
    "        all_data.extend(data)\n",
    "        offset += 5000\n",
    "        print(f\"Retrieved {len(all_data)} records...\")\n",
    "        \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP Error: {e}\")\n",
    "        break\n",
    "\n",
    "# Create final dataframe\n",
    "df = pd.DataFrame(all_data)\n",
    "df['period'] = pd.to_datetime(df['period'])\n",
    "df = df.sort_values('period', ascending=True)\n",
    "df.to_csv('georgia_generation_complete.csv', index=False)\n",
    "\n",
    "print(\"\\nData retrieval complete!\")\n",
    "print(f\"Total records retrieved: {len(df)}\")\n",
    "print(\"\\nDate range in data:\")\n",
    "print(f\"From: {df['period'].min()}\")\n",
    "print(f\"To: {df['period'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_df=pd.read_csv(r\"C:\\Users\\kaavy\\OneDrive\\Documents\\Sci4GA Internship\\georgia_generation_complete.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add location information to Energy Generation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure plant_df 'Year' is converted to a consistent format (integer)\n",
    "plant_df['Year'] = pd.to_datetime(plant_df['Year']).dt.year\n",
    "\n",
    "# Extract the year from the 'period' column in generation_df\n",
    "generation_df['Year'] = pd.to_datetime(generation_df['period']).dt.year\n",
    "\n",
    "# Merge on both 'plantCode' and 'Year'\n",
    "merged_df = pd.merge(\n",
    "    generation_df, \n",
    "    plant_df[['Plant Code', 'Year', 'Latitude', 'Longitude']], \n",
    "    left_on=['plantCode', 'Year'], \n",
    "    right_on=['Plant Code', 'Year'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop redundant 'Plant Code' column (if necessary)\n",
    "merged_df.drop(columns='Plant Code', inplace=True)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "# merged_df.to_csv('GA_Generation_with_Location_By_Year.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine How Much Emissions Each Energy Source Releases When Producing Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df = pd.read_excel(r\"C:\\Users\\kaavy\\OneDrive\\Documents\\Sci4GA Internship\\EGRID 2022 Data.xlsx\")\n",
    "emissions_ga_df = emissions_df[emissions_df['Plant state abbreviation'] == 'GA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_summary = emissions_ga_df.groupby('Plant primary fuel category')[[\n",
    "    'Plant annual NOx emissions (tons)', \n",
    "    'Plant annual SO2 emissions (tons)', \n",
    "    'Plant annual CO2 emissions (tons)'\n",
    "]].sum().reset_index()\n",
    "\n",
    "# Optional: Sort by CO2 emissions (or any other column) in descending order\n",
    "emissions_summary = emissions_summary.sort_values(by='Plant annual CO2 emissions (tons)', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(emissions_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input the data\n",
    "data = {\n",
    "    \"Energy Source\": [\"Coal\", \"Solar\", \"Natural Gas\", \"Biomass\", \"Hydroelectric\", \"Petroleum\", \"Nuclear\"],\n",
    "    \"Gross Generation (MWh)\": [361219.26, 141249.96, 1208943.9, 1169414.38, 984373.88, 111704.89, 683980],\n",
    "    \"Annual NOx Emissions (tons)\": [12228.074, 0.0, 3977.661, 4073.215, 0.0, 770.054, 0.0],\n",
    "    \"Annual SO2 Emissions (tons)\": [6921.862, 0.0, 219.629, 3990.100, 0.0, 580.035, 0.0],\n",
    "    \"Annual CO2 Emissions (tons)\": [19299720.0, 0.0, 26550080.0, 518810.7, 0.0, 252900.5, 0.0],\n",
    "    \"Count of Plants\": [2, 114, 43, 16, 30, 75, 2]\n",
    "}\n",
    "\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Emissions Intensity (Emissions per MWh)\n",
    "df[\"NOx Intensity (tons/MWh)\"] = df[\"Annual NOx Emissions (tons)\"] / df[\"Gross Generation (MWh)\"]\n",
    "df[\"SO2 Intensity (tons/MWh)\"] = df[\"Annual SO2 Emissions (tons)\"] / df[\"Gross Generation (MWh)\"]\n",
    "df[\"CO2 Intensity (tons/MWh)\"] = df[\"Annual CO2 Emissions (tons)\"] / df[\"Gross Generation (MWh)\"]\n",
    "\n",
    "\n",
    "\n",
    "### 2. Heatmap for NOx and SO2 Intensity\n",
    "# Melt the DataFrame to reshape for the heatmap\n",
    "nox_so2_df = df[[\"Energy Source\", \"NOx Intensity (tons/MWh)\", \"SO2 Intensity (tons/MWh)\"]]\n",
    "nox_so2_df_melted = nox_so2_df.melt(id_vars=[\"Energy Source\"], \n",
    "                                    var_name=\"Emission Type\", \n",
    "                                    value_name=\"Intensity\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(\n",
    "    nox_so2_df_melted.pivot(\"Energy Source\", \"Emission Type\", \"Intensity\"),\n",
    "    annot=True, fmt=\".2e\", cmap=\"Blues\", cbar_kws={'label': 'Intensity (tons/MWh)'}\n",
    ")\n",
    "plt.title(\"NOx and SO2 Intensity Heatmap by Energy Source\")\n",
    "plt.xlabel(\"Emission Type\")\n",
    "plt.ylabel(\"Energy Source\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Emissions Intensity (Emissions per MWh)\n",
    "df[\"CO2 Intensity (tons/MWh)\"] = df[\"Annual CO2 Emissions (tons)\"] / df[\"Gross Generation (MWh)\"]\n",
    "\n",
    "### 1. Heatmap for CO2 Intensity with one Emission type on X-axis\n",
    "# Adding a placeholder column to make it similar to the NOx and SO2 layout\n",
    "df_co2 = df[[\"Energy Source\", \"CO2 Intensity (tons/MWh)\"]]\n",
    "df_co2[\"Emission Type\"] = \"CO2 Intensity\"\n",
    "\n",
    "# Plot Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    df_co2.pivot(\"Energy Source\", \"Emission Type\", \"CO2 Intensity (tons/MWh)\"),\n",
    "    annot=True, fmt=\".2e\", cmap=\"Blues\", cbar_kws={'label': 'CO2 Intensity (tons/MWh)'}\n",
    ")\n",
    "plt.title(\"CO2 Intensity Heatmap by Energy Source\")\n",
    "plt.xlabel(\"Emission Type\")\n",
    "plt.ylabel(\"Energy Source\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
